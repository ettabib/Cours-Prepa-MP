\textbf{Warning: 
requires JavaScript to process the mathematics on this page.\\ If your
browser supports JavaScript, be sure it is enabled.}

\begin{center}\rule{3in}{0.4pt}\end{center}

{[}
{[}
{[}{]}
{[}

\subsubsection{12.5 Endomorphismes et formes quadratiques}

\paragraph{12.5.1 Notion d'ad\\\\jmathmathmathmathoint}

Soit E un K-espace vectoriel , \Phi une forme quadratique non dégénérée sur
E de forme polaire \phi.

Définition~12.5.1 Soit u,v \in L(E). On dit que u et v sont des
endomorphismes ad\\\\jmathmathmathmathoints si

\forall~~x,y \in E, \phi(u(x),y) = \phi(x,v(y))

Remarque~12.5.1 La symétrie de \phi montre clairement que u et v \\\\jmathmathmathmathouent des
rôles symétriques, donc que u est ad\\\\jmathmathmathmathoint de v si et seulement si~v est
ad\\\\jmathmathmathmathoint de u.

Proposition~12.5.1 Si u \in L(E) admet un ad\\\\jmathmathmathmathoint, celui-ci est unique.

Démonstration Si v1 et v2 sont ad\\\\jmathmathmathmathoints de u, on a
\forall~x,y \in E, \phi(u(x),y) = \phi(x,v1~(y)) =
\phi(x,v2(y)). On a donc \forall~~x,y \in E,
\phi(v1(y) - v2(y),x) = 0, donc pour y \in E,
v1(y) - v2(y)
\in\mathrmKer~\phi =
\0\ et donc v1 =
v2.

Définition~12.5.2 Lorsque u \in L(E) admet un ad\\\\jmathmathmathmathoint, nous le noterons
u^∗ et nous noterons L^∗(E) l'ensemble des
endomorphismes de E qui admettent un ad\\\\jmathmathmathmathoint. Il est clair que
\mathrmIdE appartient à L^∗(E)
et que \mathrmId^∗ =
\mathrmId.

Proposition~12.5.2 L^∗(E) est un sous-espace vectoriel de
L(E). L'application u\mapsto~u^∗ est un
endomorphisme involutif de L^∗(E). Si u,v \in
L^∗(E), alors u \cdot v aussi et (u \cdot v)^∗ =
v^∗\cdot u^∗.

Démonstration On a dé\\\\jmathmathmathmathà vu que la relation u et v sont ad\\\\jmathmathmathmathoints était
symétrique, donc si u \in L^∗(E), u^∗ aussi et
u^∗∗ = u. Si u,v \in L^∗(E), \alpha~,\beta~ \in K, on a

\begin{align*} \phi((\alpha~u + \beta~v)(x),y)& =& \phi(\alpha~u(x) +
\beta~v(x),y) \%& \\ & =& \alpha~\phi(u(x),y) +
\beta~\phi(v(x),y) \%& \\ & =&
\alpha~\phi(x,u^∗(y)) + \beta~\phi(x,v^∗(y))\%&
\\ & =& \phi(x,(\alpha~u^∗ +
\beta~v^∗)(y)) \%& \\
\end{align*}

ce qui montre que \alpha~u + \beta~v \in L^∗(E) et que (\alpha~u +
\beta~v)^∗ = \alpha~u^∗ + \beta~v^∗~; donc
L^∗(E) est un sous-espace vectoriel de L(E) et
u\mapsto~u^∗ est linéaire. Si u,v \in
L^∗(E), on a

\phi(u \cdot v(x),y) = \phi(v(x),u^∗(y)) = \phi(x,v^∗\cdot
u^∗(y))

ce qui montre que u \cdot v admet v^∗\cdot u^∗ comme
ad\\\\jmathmathmathmathoint.

Une des propriétés essentielles de l'ad\\\\jmathmathmathmathoint que nous utiliserons de
fa\ccon assez systématique pour la réduction des
endomorphismes est la suivante

Théorème~12.5.3 Soit u \in L^∗(E). Soit F un sous-espace de E
stable par u~; alors F^\bot est stable par u^∗.

Démonstration Soit x \in F^\bot. Si y \in F, on a
\phi(u^∗(x),y) = \phi(x,u(y)) = 0 puisque u(y) \in F et x \in
F^\bot. Donc u^∗(x) \in F^\bot et
F^\bot est stable par u^∗.

Définition~12.5.3 On dit que u \in L(E) est symétrique ou autoad\\\\jmathmathmathmathoint si
u^∗ = u. On dit que u est antisymétrique si u^∗ =
-u.

Proposition~12.5.4 L'espace L^∗(E) est somme directe du
sous-espace des endomorphismes symétriques et du sous-espace des
endomorphismes antisymétriques.

Démonstration L'endomorphisme de L^∗(E),
u\mapsto~u^∗ étant involutif, l'espace
L^∗(E) est somme directe du sous-espace propre associé à la
valeur propre 1 (les endomorphismes symétriques) et du sous-espace
propre associé à la valeur propre -1 (les endomorphismes
antisymétriques).

\paragraph{12.5.2 Ad\\\\jmathmathmathmathoint en dimension finie}

Soit E un K-espace vectoriel ~de dimension finie, \Phi une forme
quadratique non dégénérée sur E de forme polaire \phi.

Théorème~12.5.5 Tout endomorphisme de E admet un unique ad\\\\jmathmathmathmathoint
u^∗ (autrement dit L^∗(E) = L(E)). Si u \in L(E), \mathcal{E}
une base de E, \Omega =\
\mathrmMat (\phi,\mathcal{E}) et A =\
\mathrmMat (u,\mathcal{E}), alors

\mathrmMat~
(u^∗,\mathcal{E}) = \Omega^-1^tA\Omega

Démonstration Soit \mathcal{E} une base de E et \Omega =\
\mathrmMat (\phi,\mathcal{E}). Comme \phi est non dégénérée, la
matrice \Omega est inversible. Soit u,v \in L(E), A =\
\mathrmMat (u,\mathcal{E}) et B =\
\mathrmMat (v,\mathcal{E}). Si x,y \in E, on a \phi(u(x),y) =
^t(AX)\OmegaY = ^tX^tA\OmegaY et \phi(x,v(y)) =
^tX\OmegaBY . L'unicité de la matrice de la forme bilinéaire
(x,y)\mapsto~\phi(u(x),y) montre que

\begin{align*} \forall~~x,y \in E,
\phi(u(x),y) = \phi(x,v(y))& \Leftrightarrow & ^tA\Omega
= \OmegaB \%& \\ &
\Leftrightarrow & B = \Omega^-1^tA\Omega\%&
\\ \end{align*}

ce qui montre à la fois l'existence (et l'unicité) de l'ad\\\\jmathmathmathmathoint et la
formule voulue.

Remarque~12.5.2 Si la base \mathcal{E} est orthonormée, alors \Omega = In et
\mathrmMat~
(u^∗,\mathcal{E}) = ^t\
\mathrmMat (u,\mathcal{E})~; en particulier

Corollaire~12.5.6 Soit \mathcal{E} une base orthonormée de E~; alors u est
symétrique (resp. antisymétrique) si et seulement
si~\mathrmMat~ (u,\mathcal{E}) est une
matrice symétrique (resp. antisymétrique).

Corollaire~12.5.7 Si u \in L(E) est inversible, alors u^∗ est
inversible et (u^-1)^∗ =
(u^∗)^-1.

Démonstration On a u^-1 \cdot u =
\mathrmIdE d'où (u^-1 \cdot
u)^∗ = \mathrmIdE^∗, soit
u^∗\cdot (u^-1)^∗ =
\mathrmIdE. De même u \cdot u^-1 =
\mathrmIdE donne par passage à l'ad\\\\jmathmathmathmathoint
(u^-1)^∗\cdot u^∗ =
\mathrmIdE. Ceci montre que u^∗
est inversible et que (u^-1)^∗ =
(u^∗)^-1

Corollaire~12.5.8
\mathrm{det} u^∗~
= \mathrm{det}~ u,
\mathrm{tr}u^∗~
= \mathrm{tr}~u,
\chiu^∗ = \chiu.

Démonstration Soit \mathcal{E} une base de E, \Omega =\
\mathrmMat (\phi,\mathcal{E}) et A =\
\mathrmMat (u,\mathcal{E}), alors
\mathrmMat~
(u^∗,\mathcal{E}) = \Omega^-1^tA\Omega. On a donc
\mathrm{det} u^∗~
= \mathrm{det}~
\Omega^-1^tA\Omega =\
\mathrm{det} ^tA =\
\mathrm{det} A =\
\mathrm{det} u. La démonstration est la même pour la
trace et pour le polynôme caractéristique.

Proposition~12.5.9 Soit E un espace euclidien, u \in L(E). Alors

\begin{itemize}
\itemsep1pt\parskip0pt\parsep0pt
\item
  (i)
  \mathrmKeru^∗~
  =
  (\mathrmImu)^\bot~,
  \mathrmImu^∗~ =
  (\mathrmKeru)^\bot~
\item
  (ii)
  \mathrmKeru^∗~u
  = \mathrmKer~u et
  \mathrmImu^∗~u
  = \mathrmImu^∗~
\end{itemize}

Démonstration (ii) On a

\begin{align*} x
\in\mathrmKeru^∗~&
\Leftrightarrow & u^∗(x) = 0
\Leftrightarrow \forall~~y \in E,
(u^∗(x)∣y) = 0 \%&
\\ & \Leftrightarrow &
\forall~y \in E, (x\mathrel∣~u(y)) =
0 \Leftrightarrow x \in
(\mathrmImu)^\bot~\%&
\\ \end{align*}

En appliquant ce résultat à u^∗ on obtient,
\mathrmKer~u =
(\mathrmImu^∗)^\bot~
et en prenant l'orthogonal,
\mathrmImu^∗~ =
(\mathrmKeru)^\bot~

(ii) On a visiblement u(x) = 0 \rigtharrow~ u^∗u(x) = 0, donc
\mathrmKer~u
\subset~\mathrmKeru^∗~u~;
mais d'autre part, si x
\in\mathrmKeru^∗~u,
on a

\\textbar{}u(x)\\textbar{}^2 =
(u(x)∣u(x)) =
(u^∗u(x)∣x) =
(0∣x) = 0

et donc u(x) = 0, soit
\mathrmKeru^∗~u
\subset~\mathrmKer~u et l'égalité.
On en déduit alors que

\mathrmImu^∗~u =
(\mathrmKer(u^∗u)^∗)^\bot~
=
(\mathrmKeru^∗u)^\bot~
=
(\mathrmKeru)^\bot~
= \mathrmImu^∗~

\paragraph{12.5.3 Endomorphismes symétriques et formes quadratiques}

Soit E un K-espace vectoriel ~de dimension finie, \Phi une forme
quadratique non dégénérée sur E de forme polaire \phi. A tout endomorphisme
u de E, on peut associer la forme bilinéaire \psiu :
(x,y)\mapsto~\phi(x,u(y)). Il est clair que u est
symétrique (resp. antisymétrique) si et seulement si~\psiu est
une forme bilinéaire symétrique (resp. antisymétrique).

Théorème~12.5.10 L'application u\mapsto~\psiu
est un isomorphisme d'espaces vectoriels de L(E) sur l'espace
L2(E) des formes bilinéaires sur E.

Démonstration Soit \mathcal{E} une base de E, \Omega =\
\mathrmMat (\phi,\mathcal{E}) et A =\
\mathrmMat (u,\mathcal{E}). Alors \psiu(x,y) =
\phi(x,u(y)) = ^tX\OmegaAY et donc
\mathrmMat (\psiu~,\mathcal{E})
= \OmegaA. Comme l'application A\mapsto~\OmegaA est un
isomorphisme, il en est de même de
u\mapsto~\psiu.

Remarque~12.5.3 Supposons que la base \mathcal{E} est orthonormée, si bien que \Omega =
In. Alors
\mathrmMat (\psiu~,\mathcal{E})
= \mathrmMat~ (u,\mathcal{E}). Une
matrice carrée est à la fois la matrice d'un endomorphisme u de E et
d'une forme bilinéaire \psiu sur E. Mais le lecteur prendra garde
au fait que les formules de changement de bases ne sont évidemment pas
les mêmes pour l'endomorphisme
(A\mapsto~P^-1AP) et pour la forme
bilinéaire (A\mapsto~^tPAP).

\paragraph{12.5.4 Groupe orthogonal}

Soit E un K-espace vectoriel ~de dimension finie, \Phi une forme
quadratique non dégénérée sur E de forme polaire \phi.

Définition~12.5.4 On dit que u \in L(E) est un endomorphisme orthogonal si
on a les propriétés équivalentes

\begin{itemize}
\itemsep1pt\parskip0pt\parsep0pt
\item
  (i) \forall~~x \in E, \Phi(u(x)) = \Phi(x)
\item
  (ii) \forall~~x,y \in E, \phi(u(x),u(y)) = \phi(x,y)
\item
  (iii) u est inversible et u^-1 = u^∗
\item
  (iv) u \cdot u^∗ = \mathrmIdE
\item
  (v) u^∗\cdot u = \mathrmIdE
\end{itemize}

Démonstration (ii) \rigtharrow~(i) est évident (faire y = x). (i) \rigtharrow~(ii) provient de
l'identité de polarisation pour \Phi et de la linéarité de u

\begin{align*} \phi(u(x),u(y))& =& 1
\over 2 (\Phi(u(x) + u(y)) - \Phi(u(x)) - \Phi(u(y)))\%&
\\ & =& 1 \over 2
(\Phi(u(x + y)) - \Phi(u(x)) - \Phi(u(y))) \%& \\
& =& 1 \over 2 (\Phi(x + y) - \Phi(x) - \Phi(y)) = \phi(x,y)
\%& \\ \end{align*}

Pour un endomorphisme d'un espace vectoriel de dimension finie, on sait
que l'inversibilité est équivalente à l'inversibilité à gauche ou à
droite. On a donc (iii) \Leftrightarrow (iv)
\Leftrightarrow (v). Supposons (ii) vérifié. Alors \phi(x,y) =
\phi(u(x),u(y)) = \phi(x,u^∗\cdot u(y)), ce qui montre (puisque \phi est
non dégénérée) que u^∗\cdot u =
\mathrmIdE~; donc (ii) \rigtharrow~(v). De même (v)
\rigtharrow~(ii) puisque \phi(u(x),u(y)) = \phi(x,u^∗\cdot u(y)).

Remarque~12.5.4 La définition peut s'étendre au cas de la dimension
infinie, à condition d'imposer a priori que u est inversible.

Théorème~12.5.11 L'ensemble O\Phi(E) des endomorphismes
orthogonaux de E est un sous groupe de (GL(E),\cdot). Pour tout
endomorphisme orthogonal u de E, on a
\mathrm{det}~ u = ±1.
L'ensemble SO\Phi(E) des endomorphismes orthogonaux de
déterminant 1 est un sous-groupe distingué de O\Phi(E) dont les
éléments sont appelés des rotations.

Démonstration On a clairement \mathrmIdE \in
O\Phi(E). La définition (i) montre évidemment que si u et v sont
orthogonaux, il en est de même de u \cdot v. De plus, soit u \in
O\Phi(E)~; on a \Phi(u^-1(x)) = \Phi(u(u^-1(x)))
= \Phi(x) ce qui montre que u^-1 \in O\Phi(E). Donc
O\Phi(E) est un sous-groupe de (GL(E),\cdot). On a alors 1
= \mathrm{det}~
\mathrmIdE =\
\mathrm{det} (u^∗\cdot u)
= \mathrm{det}~
u^∗\mathrm{det}~ u
= (\mathrm{det}~
u)^2, soit
\mathrm{det}~ u = ±1.
L'application O\Phi(E) \rightarrow~\-
1,1\,
u\mapsto~\mathrm{det}~
u est un morphisme de groupes multiplicatifs~; son noyau
SO\Phi(E) est donc un sous-groupe distingué.

Théorème~12.5.12 On suppose qu'il existe dans E des bases orthonormées.
Soit u \in L(E).

\begin{itemize}
\itemsep1pt\parskip0pt\parsep0pt
\item
  (i) Si u est orthogonal, il envoie toute base orthonormée sur une base
  orthonormée.
\item
  (ii) Inversement, s'il existe une base orthonormée \mathcal{E} de E telle que
  u(\mathcal{E}) soit encore orthonormée, alors u est un endomorphisme orthogonal.
\end{itemize}

Démonstration (i) On a \phi(u(ei),u(e\\\\jmathmathmathmath)) =
\phi(ei,e\\\\jmathmathmathmath) = \deltai^\\\\jmathmathmathmath.

(ii) Soit x = \\sum ~
xiei \in E. On a \Phi(x) =\
\sum  xi^2~. Mais on a aussi
u(x) = \\sum ~
xiu(ei) et comme u(\mathcal{E}) est orthonormée, \Phi(u(x))
= \\sum ~
xi^2~; on a donc \forall~~x \in E,
\Phi(u(x)) = \Phi(x).

Théorème~12.5.13 Soit u un endomorphisme orthogonal et F un sous-espace
de E stable par u. Alors F^\bot est stable par u.

Démonstration On a u(F) \subset~ F et comme u est inversible, on a
dim u(F) =\ dim~ F. On
a donc u(F) = F. Soit donc x \in F^\bot et y \in F~; il existe z \in F
tel que u(z) = y, d'où \phi(u(x),y) = \phi(u(x),u(z)) = \phi(x,z) = 0, et donc
u(x) \in F^\bot.

\paragraph{12.5.5 Matrices orthogonales}

Proposition~12.5.14 Soit E un K-espace vectoriel ~de dimension finie, \Phi
une forme quadratique non dégénérée sur E de forme polaire \phi. Soit u \in
L(E), \mathcal{E} une base de E, \Omega =\
\mathrmMat (\phi,\mathcal{E}) et A =\
\mathrmMat (u,\mathcal{E}). Alors u est un endomorphisme
orthogonal si et seulement si~^tA\OmegaA = \Omega.

Démonstration On a \phi(u(x),u(y)) = ^t(AX)\Omega(AY ) =
^tX^tA\OmegaAY . L'unicité de la matrice d'une forme
bilinéaire montre que

\forall~~x,y \in E, \phi(u(x),u(y)) = \phi(x,y)
\Leftrightarrow ^tA\OmegaA = \Omega

En particulier, si \mathcal{E} est une base orthonormée de E, u est un
endomorphisme orthogonal si et seulement si~^tAA =
In. Ceci conduit à la définition suivante

Définition~12.5.5 Soit A \in MK(n)~; On dit que A est une
matrice orthogonale si elle vérifie les conditions équivalentes

\begin{itemize}
\itemsep1pt\parskip0pt\parsep0pt
\item
  (i) A est inversible et A^-1 = ^tA
\item
  (ii) ^tAA = In
\item
  (iii) A^tA = In
\end{itemize}

Théorème~12.5.15 L'ensemble OK(n) des matrices carrées
orthogonales d'ordre n est un sous groupe de (GLK(n),.). Pour
toute matrice orthogonale A, on a
\mathrm{det}~ A = ±1.
L'ensemble SOK(n) des matrices orthogonales de déterminant 1
est un sous-groupe distingué de OK(n) dont les éléments sont
appelés des matrices de rotations.

Démonstration On a clairement In \in OK(n). La
définition (i) montre évidemment que si A et B sont orthogonales, il en
est de même de AB. De plus, soit A \in OK(n)~; on a
A^-1^t(A^-1) =
A^-1^t(^tA) = A^-1A =
In ce qui montre que A^-1 \in OK(n). Donc
OK(n) est un sous-groupe de (GLK(n),.). On a alors 1
= \mathrm{det} In~
= \mathrm{det}~
(^tAA) =
(\mathrm{det}~
A)^2, soit
\mathrm{det}~ A = ±1.
L'application OK(n) \rightarrow~\-
1,1\,
A\mapsto~\mathrm{det}~
A est un morphisme de groupes multiplicatifs~; son noyau
SOK(n) est donc un sous-groupe distingué.

Dans ce paragraphe, on munira K^n de la forme bilinéaire
symétrique naturelle (qui rend la base canonique orthonormée),
c'est-à-dire que l'on posera (x∣y)
= \\sum ~
i=1^nxiyi

Théorème~12.5.16 Une matrice A \in MK(n) est orthogonale si et
seulement si~ses vecteurs colonnes (resp. lignes) forment une base
orthonormée de K^n.

Démonstration Soit
(c1,\\ldots,cn~)
les vecteurs colonnes de A,
(l1,\\ldots,ln~)
ses vecteurs lignes. On a

\begin{align*} A \in OK(n)&
\Leftrightarrow & ^tAA = I n
\Leftrightarrow \forall~~i,\\\\jmathmathmathmath,
(^tAA) i,\\\\jmathmathmathmath = \deltai^\\\\jmathmathmathmath\%&
\\ & \Leftrightarrow &
\forall~~i,\\\\jmathmathmathmath, \\sum
k=1^na k,iak,\\\\jmathmathmathmath =
\deltai^\\\\jmathmathmathmath \%& \\ &
\Leftrightarrow & \forall~~i,\\\\jmathmathmathmath,
(ci∣c\\\\jmathmathmathmath) =
\deltai^\\\\jmathmathmathmath \%& \\
\end{align*}

De la même fa\ccon, en traduisant la relation
A^tA = In, on obtiendrait
(li∣l\\\\jmathmathmathmath) =
\deltai^\\\\jmathmathmathmath.

Théorème~12.5.17 Soit E un K-espace vectoriel ~de dimension finie, \Phi une
forme quadratique non dégénérée sur E de forme polaire \phi. Soit \mathcal{E} une
base orthonormée de E, \mathcal{E}' une base de E. Alors on a équivalence de

\begin{itemize}
\itemsep1pt\parskip0pt\parsep0pt
\item
  (i) \mathcal{E}' est orthonormée
\item
  (ii) la matrice P\mathcal{E}^\mathcal{E}' de passage de la base \mathcal{E} à la
  base \mathcal{E}' est orthogonale.
\end{itemize}

Démonstration On sait que P\mathcal{E}^\mathcal{E}'
= \mathrmMat~ (u,\mathcal{E}) où u est
l'endomorphisme de E défini par \forall~~i,
u(ei) = ei'. Or d'après les résultats du paragraphe
précédent, u est un endomorphisme orthogonal si et seulement si~\mathcal{E}' est
orthonormée~; mais d'autre part, comme \mathcal{E} est orthonormée, u est
orthogonal si et seulement
si~\mathrmMat~ (u,\mathcal{E}) est une
matrice orthogonale, d'où l'équivalence entre (i) et (ii).

{[}
{[}
{[}
{[}
