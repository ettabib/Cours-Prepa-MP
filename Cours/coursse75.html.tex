\textbf{Warning: 
requires JavaScript to process the mathematics on this page.\\ If your
browser supports JavaScript, be sure it is enabled.}

\begin{center}\rule{3in}{0.4pt}\end{center}

{[}
{[}
{[}{]}
{[}

\subsubsection{13.3 Formes quadratiques hermitiennes}

\paragraph{13.3.1 Notion de forme quadratique hermitienne}

Soit E un \mathbb{C}-espace vectoriel et \phi une forme sesquilinéaire hermitienne
sur E. Soit \Phi l'application de E dans \mathbb{R}~ qui à x associe \Phi(x) = \phi(x,x)
(on a en effet \phi(x,x) = \overline\phi(x,x) donc \Phi(x) \in
\mathbb{R}~).

Proposition~13.3.1 On a les identités suivantes

\begin{itemize}
\itemsep1pt\parskip0pt\parsep0pt
\item
  (i) \Phi(\lambda~x) = \textbar{}\lambda~\textbar{}^2\Phi(x)
\item
  (ii) \Phi(x + y) = \Phi(x) +
  2\mathrmRe~(\phi(x,y)) + \Phi(y)
\item
  (ii)' \Phi(x + y) - \Phi(x - y) + i\Phi(x + iy) - i\Phi(x - iy) = 4\phi(y,x)
  (identité de polarisation)
\item
  (iii) \Phi(x + y) + \Phi(x - y) = 2(\Phi(x) + \Phi(y)) (identité de la médiane)
\end{itemize}

Démonstration (i) \Phi(\lambda~x) = \phi(\lambda~x,\lambda~x) =
\lambda~\overline\lambda~\phi(x,x) =
\textbar{}\lambda~\textbar{}^2\Phi(x)

(ii) \Phi(x + y) = \phi(x + y,x + y) = \Phi(x) + \phi(x,y) + \phi(y,x) + \Phi(y) = \Phi(x) +
2\mathrmRe~(\phi(x,y)) + \Phi(y)~;
(ii)' s'en déduit immédiatement par un petit calcul

(iii) changeant y en - y dans l'identité précédente, on a aussi \Phi(x - y)
= \Phi(x) - 2\phi(x,y) + \Phi(y), et en additionnant les deux on trouve \Phi(x + y)
+ \Phi(x - y) = 2(\Phi(x) + \Phi(y)).

Remarque~13.3.1 L'identité (ii)' montre que l'application
\phi\mapsto~\Phi est in\\\\jmathmathmathmathective de H(E) dans \mathbb{R}~^E
(espace vectoriel des applications de E dans \mathbb{R}~) puisque la connaissance
de \Phi permet de retrouver \phi. Ceci nous amène à poser

Définition~13.3.1 Soit E un \mathbb{C}-espace vectoriel . On appelle forme
quadratique hermitienne sur E toute application \Phi : E \rightarrow~ \mathbb{R}~ telle qu'il
existe une forme sesquilinéaire hermitienne \phi : E \times E \rightarrow~ \mathbb{C} vérifiant
\forall~~x \in E, \Phi(x) = \phi(x,x). Dans ce cas, \phi est
unique et est appelée la forme polaire de \Phi.

Exemple~13.3.1 Sur \mathbb{C}^n, \Phi(x) =\
\sum ~
i=1^n\textbar{}xi\textbar{}^2 est
une forme quadratique hermitienne dont la forme polaire associée est
\phi(x,y) = \\sum ~
i=1^n\overlinexiyi.
Si E désigne l'espace vectoriel des fonctions continues de {[}a,b{]}
dans \mathbb{C}, \Phi(f) =\int ~
a^b\textbar{}f(t)\textbar{}^2 dt est une forme
quadratique hermitienne dont la forme polaire est \phi(f,g)
=\int ~
a^b\overlinef(t)g(t) dt.

Proposition~13.3.2 L'ensemble Q(E) des formes quadratiques sur E est un
\mathbb{R}~-sous-espace vectoriel de \mathbb{R}~^E~; l'application
\phi\mapsto~\Phi est un isomorphisme de \mathbb{R}~-espaces
vectoriels de H(E) sur Q(E).

Remarque~13.3.2 Par la suite on confondra toutes les notions relatives à
\phi et à \Phi~: orthogonalité, matrice, non dégénérescence, isotropie~; en
particulier on posera
\mathrmKer~\Phi
= \mathrmKer~\phi =
\x \in
E∣\forall~~y \in E, \phi(x,y) =
0\. On remarquera qu'en général,
\mathrmKer\Phi\mathrel\neq~~\x
\in E∣\Phi(x) = 0\.

Théorème~13.3.3 (Pythagore). Soit E un \mathbb{C}-espace vectoriel ~et \Phi \inQ(E), \phi
la forme polaire de \Phi. Alors

x \bot\phiy \rigtharrow~ \Phi(x + y) = \Phi(x) + \Phi(y)

Démonstration C'est une conséquence évidente de l'identité \Phi(x + y) =
\Phi(x) + 2\mathrmRe~(\phi(x,y)) +
\Phi(y). Remarquons l'absence de réciproque, contrairement au cas des
formes quadratiques.

\paragraph{13.3.2 Formes quadratiques hermitiennes en dimension finie}

Soit E un \mathbb{C}-espace vectoriel ~de dimension finie, \Phi \inQ(E) de forme
polaire \phi.

Théorème~13.3.4 Soit \mathcal{E} une base de E. Alors
\mathrmMat~ (\phi,\mathcal{E}) est
l'unique matrice \Omega \in M\mathbb{C}(n) qui est hermitienne et qui vérifie

\forall~x \in E, \Phi(x) = X^∗~\OmegaX

Démonstration Il est clair que \Omega =\
\mathrmMat (\Phi,\mathcal{E}) est hermitienne et vérifie \Phi(x) =
\phi(x,x) = X^∗\OmegaX. Inversement, soit \Omega une matrice hermitienne
vérifiant cette propriété. On a alors

\phi(y,x) = 1 \over 4 (\Phi(x + y) - \Phi(x - y) + i\Phi(x + iy)
- i\Phi(x - iy)) = Y ^∗\OmegaX

(après un calcul un peu pénible) ce qui montre que \Omega
= \mathrmMat~ (\phi,\mathcal{E}).

Posons \Omega = \mathrmMat~ (\phi,\mathcal{E})
= (\omegai,\\\\jmathmathmathmath)1\leqi,\\\\jmathmathmathmath\leqn. On a alors

\phi(x,y) = \\sum
i,\\\\jmathmathmathmath\omegai,\\\\jmathmathmathmath\overlinexiy\\\\jmathmathmathmath
= \\sum
i\omegai,i\overlinexiyi
+ \\sum
i\textless{}\\\\jmathmathmathmath(\omegai,\\\\jmathmathmathmath\overlinexiy\\\\jmathmathmathmath
+ \omega\\\\jmathmathmathmath,i\overlinex\\\\jmathmathmathmathyi)

En tenant compte de \omegai,\\\\jmathmathmathmath =
\overline\omega\\\\jmathmathmathmath,i, on a donc

\Phi(x) = \phi(x,x) = \\sum
i\omegai,i\textbar{}xi\textbar{}^2 +
2\mathrmRe(\\sum
i\textless{}\\\\jmathmathmathmath\omegai,\\\\jmathmathmathmath\overlinexix\\\\jmathmathmathmath)
=
P\Phi(x1,\ldots,xn~)

Inversement, soit P de la forme
P(x1,\\ldots,xn~)
= \\sum ~
i=1^nai,i\textbar{}xi\textbar{}^2
+
2\mathrmRe~(\\\sum

i\textless{}\\\\jmathmathmathmathai,\\\\jmathmathmathmath\overlinexix\\\\jmathmathmathmath).
Définissons \phi sur E par

\phi(x,y) = \\sum
iai,i\overlinexiyi
+ \\sum
i\textless{}\\\\jmathmathmathmath(ai,\\\\jmathmathmathmath\overlinexiy\\\\jmathmathmathmath
+
\overlineai,\\\\jmathmathmathmath\overlinex\\\\jmathmathmathmathyi)

si x = \\sum ~
xiei et y =\
\sum  yiei~. Alors \phi est
clairement une forme sesquilinéaire hermitienne sur E et la forme
quadratique associée vérifie \Phi(x) =
P(x1,\\ldots,xn~).
On obtient l'expression de \phi(x,y) à partir de l'expression polynomiale
de \Phi(x) en rempla\ccant partout les termes carrés
\textbar{}xi\textbar{}^2 par
\overlinexiyi et les termes
rectangles
\mathrmRe(ai,\\\\jmathmathmathmath\overlinexix\\\\jmathmathmathmath~)
par  1 \over 2
(ai,\\\\jmathmathmathmath\overlinexix\\\\jmathmathmathmath +
\overlineai,\\\\jmathmathmathmath\overlinex\\\\jmathmathmathmathyi).

Théorème~13.3.5 Si \mathcal{E} est une base orthonormée de E (c'est à dire
\phi(ei,e\\\\jmathmathmathmath) = \deltai^\\\\jmathmathmathmath), alors
\mathrmMat~ (\phi,\mathcal{E}) =
In, \phi(x,y) = X^∗Y =\
\sum ~
i=1^n\overlinexiyi
et \Phi(x) = X^∗X =\
\sum ~
i=1^n\textbar{}xi\textbar{}^2.

Démonstration Evident.

\paragraph{13.3.3 Formes quadratiques hermitiennes définies positives}

Définition~13.3.2 Soit E un \mathbb{C} espace vectoriel et \Phi une forme
quadratique hermitienne sur E. On dit que \Phi est définie positive si
\forall~x \in E \diagdown\0\~,
\Phi(x) \textgreater{} 0.

Théorème~13.3.6 (inégalité de Schwarz). Soit E un \mathbb{C} espace vectoriel et
\Phi une forme quadratique hermitienne définie positive sur E de forme
polaire \phi. Alors

\forall~~x,y \in E,
\textbar{}\phi(x,y)\textbar{}^2 \leq \Phi(x)\Phi(y)

avec égalité si et seulement si~la famille (x,y) est liée.

Démonstration L'inégalité est évidente si y = 0~; supposons donc
y\neq~0. Soit \theta \in \mathbb{R}~. On écrit
\forall~t \in \mathbb{R}~, \Phi(x + te^i\theta~y) ≥ 0, soit
encore t^2\Phi(y) +
2t\mathrmRe(e^i\theta~\phi(x,y))
+ \Phi(x) ≥ 0. Choisissons \theta tel que \phi(x,y) =
e^-i\theta\textbar{}\phi(x,y)\textbar{} (autrement dit l'opposé d'un
argument de \phi(x,y)). On a donc t^2\Phi(y) +
2t\textbar{}\phi(x,y)\textbar{} + \Phi(x) ≥ 0. Ce trinome du second degré doit
donc avoir un discriminant réduit négatif, soit
\textbar{}\phi(x,y)\textbar{}^2 - \Phi(x)\Phi(y) \leq 0. Si on a
l'égalité, deux cas sont possibles. Soit y = 0 auquel cas la famille
(x,y) est liée, soit \Phi(y)\neq~0~; mais dans ce
cas ce trinome en t a une racine double t0, et donc \Phi(x +
t0e^i\thetay) = 0 d'où x + t0e^i\thetay
= 0 et donc la famille est liée. Inversement, si la famille (x,y) est
liée, on a par exemple x = \lambda~y et dans ce cas
\textbar{}\phi(x,y)\textbar{}^2 =
\textbar{}\lambda~^2\textbar{}\Phi(y)^2 = \Phi(x)\Phi(y).

Théorème~13.3.7 (inégalité de Minkowski). Soit E un \mathbb{C} espace vectoriel
et \Phi une forme quadratique hermitienne définie positive sur E. Alors

\forall~x,y \in E, \sqrt\Phi(x + y)~
\leq\sqrt\Phi(x) + \sqrt\Phi(y)

avec égalité si et seulement si~la famille (x,y) est positivement liée.

Démonstration On a

\begin{align*} \Phi(x + y)& =& \Phi(x) +
2\mathrmRe~(\phi(x,y)) +
\Phi(y)\%& \\ & \leq& \Phi(x) +
2\textbar{}\phi(x,y)\textbar{} + \Phi(y) \%& \\
& \leq& \Phi(x) + 2\sqrt\Phi(x)\Phi(y) + \Phi(y)\%&
\\ & =& \left
(\sqrt\Phi(x) +
\sqrt\Phi(y)\right )^2 \%&
\\ \end{align*}

d'où \sqrt\Phi(x + y) \leq\sqrt\Phi(x) +
\sqrt\Phi(y). L'égalité nécessite à la fois que
\textbar{}\phi(x,y)\textbar{} = \sqrt\Phi(x)\Phi(y), donc que
(x,y) soit liée, et que
\mathrmRe~(\phi(x,y)) =
\textbar{}\phi(x,y)\textbar{}≥ 0, c'est-à-dire que le coefficient de
proportionnalité soit réel et positif.

Définition~13.3.3 On appelle espace préhilbertien complexe un couple
(E,\Phi) d'un \mathbb{C}-espace vectoriel ~E et d'une forme quadratique hermitienne
définie positive sur E. On appelle espace hermitien un espace
préhilbertien complexe de dimension finie.

Théorème~13.3.8 Soit (E,\Phi) un espace préhilbertien complexe. Alors
l'application x\mapsto~\sqrt\Phi(x)
est une norme sur E appelée norme hermitienne.

Démonstration La propriété de séparation provient du fait que \Phi est
définie. L'homogénéité provient de l'homogénéité de la forme
quadratique. Quant à l'inégalité triangulaire, ce n'est autre que
l'inégalité de Minkowski.

Définition~13.3.4 On notera (x∣y) = \phi(x,y) et
\\textbar{}x\\textbar{}^2 =
(x∣x) = \Phi(x)

\paragraph{13.3.4 Espaces hermitiens}

Une forme définie positive étant clairement non dégénérée, on a bien
évidemment

Théorème~13.3.9 Soit E un espace hermitien. Pour toute forme linéaire f
sur E, il existe un unique vecteur vf \in E tel que
\forall~~x \in E, f(x) =
(vf∣x)

D'autre part si \Phi est définie positive, et si A est un sous-espace
vectoriel de E on a

x \in A \bigcap A^\bot\rigtharrow~ x \bot x \rigtharrow~ (x∣x) = 0 \rigtharrow~ x
= 0

Comme de plus dim~ A +\
dim A^\bot = dim~ E, on obtient

Théorème~13.3.10 Soit E un espace hermitien.Pour tout sous-espace
vectoriel A de E, on a E = A \oplus~ A^\bot et
(A^\bot)^\bot = A.

Enfin l'existence de bases orthonormées nous est garanti par
l'algorithme de Gramm-Schmidt, dont la démonstration est strictement la
même que pour les formes quadratiques~:

Théorème~13.3.11 Soit E un espace hermitien. Soit \mathcal{E} =
(e1,\\ldots,en~)
une base de E. Alors il existe une base orthonormée \mathcal{E}' =
(\epsilon1,\\ldots,\epsilonn~)
de E vérifiant les conditions équivalentes suivantes

\begin{itemize}
\itemsep1pt\parskip0pt\parsep0pt
\item
  (i) \forall~k \in {[}1,n{]}, \epsilonk~
  \in\mathrmVect(e1,\\\ldots,ek~)
\item
  (ii) \forall~~k \in {[}1,n{]},
  \mathrmVect(\epsilon1,\\\ldots,\epsilonk~)
  =\
  \mathrmVect(e1,\\ldots,ek~)
\item
  (iii) la matrice de passage de \mathcal{E} à \mathcal{E}' est triangulaire supérieure
\end{itemize}

Si \mathcal{E}' =
(\epsilon1,\\ldots,\epsilonn~)
et \mathcal{E}'' =
(\eta1,\\ldots,\etan~)
sont deux telles bases orthonormées, il existe des scalaires
\lambda~1,\\ldots,\lambda~n~
de module 1 tels que \forall~~i \in {[}1,n{]},
\etai = \lambda~i\epsiloni.

{[}
{[}
{[}
{[}
